{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third-party\n",
    "from astropy.table import Table\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.constants import G\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "# plt.style.use('notebook.mplstyle')\n",
    "plt.style.use('apw-notebook')\n",
    "%matplotlib inline\n",
    "import corner\n",
    "import emcee\n",
    "from scipy.integrate import quad\n",
    "from scipy.misc import logsumexp\n",
    "import schwimmbad\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tgas = Table.read('../data/tgas.csv')\n",
    "tgas['hd_id'] = ['240430', '240429']\n",
    "\n",
    "# From John Brewer:\n",
    "tgas['rv'] = -21.2 # km/s\n",
    "tgas['rv_error'] = 0.1 # km/s\n",
    "\n",
    "# Test a: move star 2 at fixed 3d velocity\n",
    "# new_parallax = 2.\n",
    "# tgas[1]['pmra'] = (tgas[1]['pmra']/tgas[1]['parallax']) * new_parallax\n",
    "# tgas[1]['pmdec']  = (tgas[1]['pmdec']/tgas[1]['parallax']) * new_parallax\n",
    "# tgas[1]['parallax'] = new_parallax # make them separated by 100s of pc\n",
    "# tgas[1]['parallax_error'] = 0.05\n",
    "\n",
    "# Test b: keep stars near each other, resample velocity of star 2\n",
    "# tgas[1]['pmra'] = np.random.normal(0, 25) * tgas[1]['parallax']/4.74\n",
    "# tgas[1]['pmdec'] = np.random.normal(0, 25) * tgas[1]['parallax']/4.74\n",
    "# tgas[1]['rv'] = np.random.normal(0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_hat(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'ra'], units=None):\n",
    "    y = np.zeros(len(names))\n",
    "        \n",
    "    default_units = dict()\n",
    "    default_units['ra'] = u.degree\n",
    "    default_units['dec'] = u.degree\n",
    "    default_units['parallax'] = u.mas\n",
    "    default_units['pmra'] = u.mas/u.yr\n",
    "    default_units['pmdec'] = u.mas/u.yr\n",
    "    default_units['rv'] = u.km/u.s\n",
    "    \n",
    "    if units is None:\n",
    "        units = [default_units[name] for name in names]\n",
    "    \n",
    "    for i,name in enumerate(names):\n",
    "        y[i] = (row[name]*default_units[name]).to(units[i]).value\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cov(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'ra'], units=None):\n",
    "    \n",
    "    default_err_units = dict()\n",
    "    default_err_units['ra'] = u.mas\n",
    "    default_err_units['dec'] = u.mas\n",
    "    default_err_units['parallax'] = u.mas\n",
    "    default_err_units['pmra'] = u.mas/u.yr\n",
    "    default_err_units['pmdec'] = u.mas/u.yr\n",
    "    default_err_units['rv'] = u.km/u.s\n",
    "    \n",
    "    if units is None:\n",
    "        units = [default_err_units[name] for name in names]\n",
    "    \n",
    "    C = np.zeros((len(names), len(names)))\n",
    "\n",
    "    # pre-load the diagonal\n",
    "    for i,name in enumerate(names):\n",
    "        full_name = \"{}_error\".format(name)\n",
    "        C[i,i] = (row[full_name]*default_err_units[name]).to(units[i]).value**2\n",
    "\n",
    "    for i,name1 in enumerate(names):\n",
    "        for j,name2 in enumerate(names):\n",
    "            if j <= i:\n",
    "                continue\n",
    "                \n",
    "            if full_name not in row: # skip if no correlations exist\n",
    "                continue\n",
    "                \n",
    "            full_name = \"{}_{}_corr\".format(name1, name2)\n",
    "            u_old = default_err_units[name1]*default_err_units[name2]\n",
    "            u_new = units[i]*units[j]\n",
    "            C[i,j] = (row[full_name] * np.sqrt(C[i,i]*C[j,j]) * u_old).to(u_new).value\n",
    "            C[j,i] = (row[full_name] * np.sqrt(C[i,i]*C[j,j]) * u_old).to(u_new).value\n",
    "            \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProbModel(object):\n",
    "        \n",
    "    def ln_posterior(self, pars):\n",
    "        \"\"\" \n",
    "        Up to a normalization constant, the log of the posterior pdf is just \n",
    "        the sum of the log likelihood plus the log prior.\n",
    "        \"\"\"\n",
    "        lnp = self.ln_prior(pars)\n",
    "        if np.isinf(lnp): # short-circuit if the prior is infinite (don't bother computing likelihood)\n",
    "            return lnp\n",
    "\n",
    "        lnL = self.ln_likelihood(pars).sum()\n",
    "        lnprob = lnp + lnL\n",
    "\n",
    "        if np.isnan(lnprob):\n",
    "            return -np.inf\n",
    "\n",
    "        return lnprob\n",
    "    \n",
    "    def __call__(self, pars):\n",
    "        return self.ln_posterior(pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component 1: wide binary\n",
    "\n",
    "The stars are a wide binary, drawn from the separation distribution \n",
    "$$\n",
    "p(\\Delta x) \\propto (\\Delta x)^{-1} \\quad ; \\quad 10^{-4}<\\Delta x<10~{\\rm pc}\n",
    "$$\n",
    "\n",
    "### Component 2: co-moving pair\n",
    "\n",
    "The stars are co-moving but not necessarily *bound*\n",
    "\n",
    "### Component 3: chance alignment\n",
    "\n",
    "The stars are individually drawn from the field population\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmspc_to_masyr = 210.94953\n",
    "masyr_to_kmspc = 1/kmspc_to_masyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xv_to_y(x, v):\n",
    "    dist = np.linalg.norm(x)\n",
    "    y = np.array([np.arctan2(x[1], x[0]) % (2*np.pi), # rad\n",
    "                  np.arcsin(x[2] / dist), # rad\n",
    "                  1000. / dist, # mas\n",
    "                  v[0] / dist * kmspc_to_masyr, # mas/yr\n",
    "                  v[1] / dist * kmspc_to_masyr, # mas/yr\n",
    "                  v[2]]) # km/s\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MixtureModel(ProbModel):\n",
    "    \n",
    "    def __init__(self, tgas_rows, mass=[1., 1.]*u.Msun, mass_err=[0.01,0.01]*u.Msun,\n",
    "                 sigma_v=25.*u.km/u.s): \n",
    "        \"\"\"\n",
    "        TODO: the right thing to do is to rotate (vra,vdec,vr) to (vx,vy,vz), but\n",
    "            this is ok at the ~10 m/s level (given their small sky separation)\n",
    "            \n",
    "        TODO: update masses\n",
    "        \"\"\" \n",
    "        assert len(tgas_rows) == 2\n",
    "        \n",
    "        self.y_hats = []\n",
    "        self.Covs = []\n",
    "        self.Cinvs = []\n",
    "        self._uvecs = []\n",
    "        self._logdets = []\n",
    "        \n",
    "        for row in tgas_rows:\n",
    "            y_hat = get_y_hat(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'rv'],\n",
    "                              units=[u.rad, u.rad, u.mas, u.mas/u.yr, u.mas/u.yr, u.km/u.s])\n",
    "            Cov = get_cov(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'rv'],\n",
    "                          units=[u.rad, u.rad, u.mas, u.mas/u.yr, u.mas/u.yr, u.km/u.s])\n",
    "            _,log_det = np.linalg.slogdet(2*np.pi*Cov)\n",
    "            \n",
    "            rep = coord.UnitSphericalRepresentation(lon=row['ra']*u.deg, \n",
    "                                                    lat=row['dec']*u.deg)\n",
    "            uvec = rep.represent_as(coord.CartesianRepresentation).xyz.value\n",
    "            \n",
    "            \n",
    "            self.y_hats.append(y_hat)\n",
    "            self.Covs.append(Cov)\n",
    "            self.Cinvs.append(np.linalg.inv(Cov))\n",
    "            self._uvecs.append(uvec)\n",
    "            self._logdets.append(log_det)\n",
    "        \n",
    "        # masses\n",
    "        self.mass = mass.to(u.Msun).value\n",
    "        self.mass_err = mass_err.to(u.Msun).value\n",
    "        self._tot_mass = np.sum(self.mass)\n",
    "        self._Mred = np.prod(self.mass) / self._tot_mass # reduced mass\n",
    "        \n",
    "        # sky separation\n",
    "        coords = coord.SkyCoord(ra=tgas_rows['ra']*u.deg, \n",
    "                                dec=tgas_rows['dec']*u.deg)\n",
    "        self._cos_sep = np.cos(coords[1].separation(coords[0]))\n",
    "                \n",
    "        # some assumed parameters\n",
    "        self._G = G.to(u.pc/u.Msun*u.km**2/u.s**2).value\n",
    "        self.sigma_v = sigma_v.to(u.km/u.s).value\n",
    "    \n",
    "    # ======\n",
    "    # Priors\n",
    "    # ======\n",
    "    def ln_p_lndx(self, lndx, lnmin=np.log(1E-4), lnmax=np.log(1E1)): # units are pc\n",
    "        if lndx < lnmin or lndx > lnmax:\n",
    "            return -np.inf\n",
    "        return -np.log(lnmax-lnmin)\n",
    "    \n",
    "    def ln_p_x(self, x, x_max=1000., x_min=-1000.):\n",
    "        if np.any(x < x_min) or np.any(x > x_max):\n",
    "            return -np.inf\n",
    "        return -len(x) * np.log(x_max-x_min)\n",
    "    \n",
    "    def unpack_pars(self, pars):\n",
    "        \"\"\"\n",
    "        We sample over the 6D Cartesian phase-space parameters of the barycenter\n",
    "        of the pair and the separation from star1 to star2 -- that is, the \n",
    "        separation is defined as positive from star1 to star2. \n",
    "        \n",
    "        Positions are in [pc]\n",
    "        Velocities in [km/s]\n",
    "        Masses in [Msun]\n",
    "        \"\"\"\n",
    "        (x, y, z, vx, vy, vz, # barycenter parameters\n",
    "         dx, dy, dz, dvx, dvy, dvz, # separation parameters\n",
    "         M1, M2, # masses\n",
    "         f1, f2) = pars\n",
    "        \n",
    "        # construct 6D vectors of phase-space coordinates\n",
    "        w_bary = np.array([x, y, z, vx, vy, vz])\n",
    "        dw = np.array([dx, dy, dz, dvx, dvy, dvz])\n",
    "        \n",
    "        # mass ratio factors\n",
    "        fac1 = self._Mred / self.mass[0]\n",
    "        fac2 = self._Mred / self.mass[1]\n",
    "        \n",
    "        # position, velocity of star 1, star2:\n",
    "        w1 = w_bary - fac1*dw\n",
    "        w2 = w_bary + fac2*dw\n",
    "        \n",
    "        mix_weights = [f1, f2, 1-(f1+f2)]\n",
    "        \n",
    "        return w_bary, dw, w1, w2, [M1, M2], mix_weights\n",
    "    \n",
    "    def ln_component1(self, w_bary, dw, x1, v1, x2, v2):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood for component 1 of the mixture model:\n",
    "        wide binary\n",
    "\n",
    "        - For case (1) the only parameters that matter are |\u2206x| and the\n",
    "        direction of \u2206v (assuming circular orbit), so I use the wide-binary\n",
    "        separation distribution on |\u2206x| and assume isotropic in direction of\n",
    "        \u2206v (so here |\u2206v| is unconstrained / ignored, but we infer the\n",
    "        direction?).\n",
    "        \"\"\"\n",
    "        \n",
    "        a_x = np.linalg.norm(dw[:3])\n",
    "        a_v = 2*np.sqrt(self._G * self._tot_mass / a_x) # km/s\n",
    "        \n",
    "        # velocity separation set by separation and masses\n",
    "        dv = a_v * dw[3:] / np.linalg.norm(dw[3:])\n",
    "        fac1 = self._Mred / self.mass[0]\n",
    "        fac2 = self._Mred / self.mass[0]\n",
    "        v1 = w_bary[3:] - fac1*dv\n",
    "        v2 = w_bary[3:] + fac2*dv\n",
    "                \n",
    "        # prior terms\n",
    "        ln_p = 0.\n",
    "        ln_p += self.ln_p_lndx(a_x) # TODO: is this a switch to spherical? might be improper..\n",
    "        ln_p += self.ln_p_x(w_bary[:3])\n",
    "        ln_p += -0.5 * np.sum(w_bary[3:]**2 / self.sigma_v**2 + np.log(2*np.pi*self.sigma_v**2))\n",
    "        \n",
    "        if not np.isfinite(ln_p):\n",
    "            return -np.inf\n",
    "        \n",
    "        # convert Cartesian to [ra, dec, parallax, mu_ra, mu_dec, rv]\n",
    "        dy1 = self.y_hats[0] - xv_to_y(x1, v1)\n",
    "        dy2 = self.y_hats[1] - xv_to_y(x2, v2)\n",
    "        \n",
    "        # likelihood terms\n",
    "        ln_l = 0.\n",
    "        ln_l += -0.5 * self._logdets[0] - 0.5 * dy1.T @ self.Cinvs[0] @ dy1\n",
    "        ln_l += -0.5 * self._logdets[1] - 0.5 * dy2.T @ self.Cinvs[1] @ dy2\n",
    "        \n",
    "        return ln_p + ln_l\n",
    "        \n",
    "    def ln_component2(self, w_bary, dw, x1, v1, x2, v2):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood for component 2 of the mixture model:\n",
    "        unbound but comoving\n",
    "        \n",
    "        - In case (2) I can do the same with positions as above, and then\n",
    "        assume v1=v2=v_bary (so here \u2206v is unconstrained / ignored?).\n",
    "        \"\"\"\n",
    "        \n",
    "        v1 = v2 = w_bary[3:]\n",
    "        \n",
    "        # prior terms\n",
    "        ln_p = 0.\n",
    "        ln_p += self.ln_p_x(x1)\n",
    "        ln_p += self.ln_p_x(x2)\n",
    "        ln_p += -0.5 * np.sum(v1**2 / self.sigma_v**2 + np.log(2*np.pi*self.sigma_v**2))\n",
    "        \n",
    "        if not np.isfinite(ln_p):\n",
    "            return -np.inf\n",
    "        \n",
    "        # convert Cartesian to [ra, dec, parallax, mu_ra, mu_dec, rv]\n",
    "        dy1 = self.y_hats[0] - xv_to_y(x1, v1)\n",
    "        dy2 = self.y_hats[1] - xv_to_y(x2, v2)\n",
    "        \n",
    "        # likelihood terms\n",
    "        ln_l = 0.\n",
    "        ln_l += -0.5 * self._logdets[0] - 0.5 * dy1.T @ self.Cinvs[0] @ dy1\n",
    "        ln_l += -0.5 * self._logdets[1] - 0.5 * dy2.T @ self.Cinvs[1] @ dy2\n",
    "        \n",
    "        return ln_p + ln_l\n",
    "    \n",
    "    def ln_component3(self, w_bary, dw, x1, v1, x2, v2):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood for component 3 of the mixture model:\n",
    "        two independent draws from the field population\n",
    "        \n",
    "        - In case (3) when they're both field stars, I can just transform to\n",
    "        (x1, x2, v1, v2) and evaluate the priors independently on the\n",
    "        full-space positions and velocities.\n",
    "        \"\"\"\n",
    "        \n",
    "        # prior terms\n",
    "        ln_p = 0.\n",
    "        ln_p += self.ln_p_x(x1)\n",
    "        ln_p += self.ln_p_x(x2)\n",
    "        ln_p += -0.5 * np.sum(v1**2 / self.sigma_v**2 + np.log(2*np.pi*self.sigma_v**2))\n",
    "        ln_p += -0.5 * np.sum(v2**2 / self.sigma_v**2 + np.log(2*np.pi*self.sigma_v**2))\n",
    "        \n",
    "        if not np.isfinite(ln_p):\n",
    "            return -np.inf\n",
    "        \n",
    "        # convert Cartesian to [ra, dec, parallax, mu_ra, mu_dec, rv]\n",
    "        dy1 = self.y_hats[0] - xv_to_y(x1, v1)\n",
    "        dy2 = self.y_hats[1] - xv_to_y(x2, v2)\n",
    "        \n",
    "        # likelihood terms\n",
    "        ln_l = 0.\n",
    "        ln_l += -0.5 * self._logdets[0] - 0.5 * dy1.T @ self.Cinvs[0] @ dy1\n",
    "        ln_l += -0.5 * self._logdets[1] - 0.5 * dy2.T @ self.Cinvs[1] @ dy2\n",
    "        \n",
    "        return ln_p + ln_l\n",
    "        \n",
    "    def ln_likelihood(self, pars):\n",
    "        w_bary, dw, w1, w2, masses, mix_weights = self.unpack_pars(pars)\n",
    "        \n",
    "        x1 = w1[:3]\n",
    "        v1 = w1[3:]\n",
    "        x2 = w2[:3]\n",
    "        v2 = w2[3:]\n",
    "        \n",
    "        lnprob1 = self.ln_component1(w_bary, dw, x1, v1, x2, v2)\n",
    "#         lnprob2 = self.ln_component2(w_bary, dw, x1, v1, x2, v2)\n",
    "        lnprob3 = self.ln_component3(w_bary, dw, x1, v1, x2, v2)\n",
    "#         lnprobs = [lnprob1, lnprob2, lnprob3]\n",
    "        lnprobs = [lnprob1, -9999999., lnprob3]\n",
    "        \n",
    "        if np.any(np.logical_not(np.isfinite(lnprobs))):\n",
    "            return np.array([-np.inf])\n",
    "        \n",
    "        # masses\n",
    "        ll = -0.5 * np.sum((masses - self.mass)**2 / self.mass_err**2 + np.log(2*np.pi*self.mass_err**2))\n",
    "        \n",
    "        return ll + logsumexp(lnprobs, b=mix_weights)\n",
    "\n",
    "    def ln_prior(self, pars):\n",
    "        w_bary, dw, w1, w2, masses, mix_weights = self.unpack_pars(pars)\n",
    "        # HACK!!\n",
    "        \n",
    "        lp = 0.\n",
    "        \n",
    "        # uniform prior on weights\n",
    "        if (mix_weights[0] < 0 or mix_weights[0] > 1. or \n",
    "            mix_weights[1] < 0 or mix_weights[1] > 1 or \n",
    "            (mix_weights[0]+mix_weights[1]) > 1):\n",
    "            return -np.inf\n",
    "        \n",
    "        return lp\n",
    "    \n",
    "    def get_p0(self, size=1, scale=1E-3):\n",
    "        try:\n",
    "            len(size)\n",
    "        except:\n",
    "            size = (size,)\n",
    "        p0 = np.zeros(size+(16,))\n",
    "        \n",
    "        y_hats = [np.random.multivariate_normal(yh, (1E-3)**2*Cov, size=size)\n",
    "                  for yh,Cov in zip(self.y_hats, self.Covs)]\n",
    "        \n",
    "        ws = []\n",
    "        for yh in y_hats:\n",
    "            yh = yh.T\n",
    "            d = 1000./yh[2]\n",
    "            w = [d*np.cos(yh[0])*np.cos(yh[1]),\n",
    "                 d*np.sin(yh[0])*np.cos(yh[1]),\n",
    "                 d*np.sin(yh[1]),\n",
    "                 4.74047*yh[3]/yh[2], \n",
    "                 4.74047*yh[4]/yh[2], \n",
    "                 yh[5]]\n",
    "            ws.append(np.array(w).T)\n",
    "            \n",
    "        dw = ws[1]-ws[0]\n",
    "        w_bary = (self.mass[0]*ws[0] + self.mass[1]*ws[1]) / self._tot_mass\n",
    "        p0[...,:6] = w_bary\n",
    "        p0[...,6:12] = dw\n",
    "        p0[...,12:14] = np.random.normal(self.mass, self.mass_err*scale, size=size+(2,))\n",
    "        p0[...,14:16] = np.random.normal([0.5,0.1], scale, size=size+(2,))\n",
    "        \n",
    "        return np.squeeze(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MixtureModel(tgas, mass=[1., 1.07]*u.Msun, mass_err=[0.01, 0.01]*u.Msun,\n",
    "                     sigma_v=25*u.km/u.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = model.get_p0()\n",
    "ndim = len(p0)\n",
    "model.ln_likelihood(p0), model.ln_prior(p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard ensemble sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 256\n",
    "n_burnin = 512\n",
    "n_mcmc = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# all_p0 = model.get_p0(size=nwalkers)\n",
    "# ndim = all_p0.shape[1]\n",
    "# with schwimmbad.MultiPool() as pool:\n",
    "#     sampler = emcee.EnsembleSampler(nwalkers, ndim, model, pool=pool)\n",
    "    \n",
    "#     for res in tqdm.tqdm_notebook(sampler.sample(all_p0, iterations=n_burnin), desc='Burn-in'):\n",
    "#         pass\n",
    "    \n",
    "#     pos,_,_ = res\n",
    "#     sampler.reset()\n",
    "    \n",
    "#     for res in tqdm.tqdm_notebook(sampler.sample(pos, iterations=n_mcmc), desc='Production'):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_plot_walkers = 128\n",
    "# alpha = 0.1\n",
    "\n",
    "# fig,axes = plt.subplots(6, 3, figsize=(15,15), sharex=True)\n",
    "\n",
    "# for k in range(0,6):\n",
    "#     for j in range(n_plot_walkers):\n",
    "#         axes[k,0].plot(sampler.chain[j,:,k], marker='', alpha=alpha, \n",
    "#                        drawstyle='steps-mid', color='k')\n",
    "        \n",
    "# for k in range(0,6):\n",
    "#     for j in range(n_plot_walkers):\n",
    "#         axes[k,1].plot(sampler.chain[j,:,k+6], marker='', alpha=alpha, \n",
    "#                        drawstyle='steps-mid', color='k')\n",
    "        \n",
    "# for k in range(0,4):\n",
    "#     for j in range(n_plot_walkers):\n",
    "#         axes[k,2].plot(sampler.chain[j,:,k+12], marker='', alpha=alpha, \n",
    "#                        drawstyle='steps-mid', color='k')\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# axes[-1,-1].set_visible(False)\n",
    "\n",
    "# fig.savefig('../plots/trace.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # flatchain = sampler.flatchain[:,[0,1,2,3,8,9,10]]\n",
    "# flatchain = sampler.flatchain\n",
    "# flatchain = np.vstack((flatchain.T, 1-(flatchain[:,-2]+flatchain[:,-1]))).T\n",
    "\n",
    "# fig = corner.corner(flatchain, bins=64, plot_datapoints=False,\n",
    "#                     labels=['$r_1$ [pc]', r'$v_{\\alpha,1}$ [km/s]', r'$v_{\\delta,1}$ [km/s]', '$v_{r,1}$ [km/s]', \n",
    "#                             '$r_2$ [pc]', r'$v_{\\alpha,2}$ [km/s]', r'$v_{\\delta,2}$ [km/s]', '$v_{r,2}$ [km/s]', \n",
    "#                             r'$\\ln a/{\\rm pc}$', '$f_1$ (bound)', '$f_2$ (comoving)', '$f_3$ (field)'])\n",
    "# del fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PTSampler instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntemps = 32\n",
    "betas = np.logspace(0, -8, ntemps)\n",
    "nwalkers = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_burnin = 1024\n",
    "n_mcmc = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_p0 = model.get_p0(size=(ntemps,nwalkers))\n",
    "ndim = all_p0.shape[-1]\n",
    "with schwimmbad.MultiPool() as pool:\n",
    "    pt_sampler = emcee.PTSampler(ntemps, nwalkers, ndim, \n",
    "                                 model.ln_likelihood, model.ln_prior,\n",
    "                                 betas=betas, pool=pool)\n",
    "    \n",
    "    for res in tqdm.tqdm_notebook(pt_sampler.sample(all_p0, iterations=n_burnin), desc='Burn-in'):\n",
    "        pass\n",
    "    \n",
    "    pos,_,_ = res\n",
    "    pt_sampler.reset()\n",
    "    \n",
    "    for res in tqdm.tqdm_notebook(pt_sampler.sample(pos, iterations=n_mcmc), desc='Production'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot_walkers = 128\n",
    "alpha = 0.1\n",
    "\n",
    "fig,axes = plt.subplots(6, 3, figsize=(15,15), sharex=True)\n",
    "\n",
    "temp = 0\n",
    "\n",
    "for k in range(0,6):\n",
    "    for j in range(n_plot_walkers):\n",
    "        axes[k,0].plot(pt_sampler.chain[temp,j,:,k], marker='', alpha=alpha, \n",
    "                       drawstyle='steps-mid', color='k')\n",
    "        \n",
    "for k in range(0,6):\n",
    "    for j in range(n_plot_walkers):\n",
    "        axes[k,1].plot(pt_sampler.chain[temp,j,:,k+6], marker='', alpha=alpha, \n",
    "                       drawstyle='steps-mid', color='k')\n",
    "        \n",
    "for k in range(0,4):\n",
    "    for j in range(n_plot_walkers):\n",
    "        axes[k,2].plot(pt_sampler.chain[temp,j,:,k+12], marker='', alpha=alpha, \n",
    "                       drawstyle='steps-mid', color='k')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[-1,-1].set_visible(False)\n",
    "\n",
    "fig.savefig('../plots/trace_pt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatchain = np.vstack(pt_sampler.chain[0])\n",
    "flatchain = np.vstack((flatchain.T, 1-(flatchain[:,-2]+flatchain[:,-1]))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(flatchain, bins=64, plot_datapoints=False)\n",
    "#                     labels=['$r_1$ [pc]', r'$v_{\\alpha,1}$ [km/s]', r'$v_{\\delta,1}$ [km/s]', '$v_{r,1}$ [km/s]', \n",
    "#                             '$r_2$ [pc]', r'$v_{\\alpha,2}$ [km/s]', r'$v_{\\delta,2}$ [km/s]', '$v_{r,2}$ [km/s]', \n",
    "#                             r'$\\ln a/{\\rm pc}$', '$f_1$ (bound)', '$f_2$ (comoving)', '$f_3$ (field)'])\n",
    "fig.savefig('../plots/corner.png')\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.sqrt(np.sum(flatchain[:,6:9]**2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('pt_chain_temp0.npy', pt_sampler.chain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = np.random.dirichlet(alpha=[2,1,1], size=100000)\n",
    "_ = corner.corner(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}