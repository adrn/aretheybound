{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third-party\n",
    "from astropy.table import Table\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.constants import G\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np\n",
    "# plt.style.use('notebook.mplstyle')\n",
    "plt.style.use('apw-notebook')\n",
    "%matplotlib inline\n",
    "import corner\n",
    "import emcee\n",
    "from scipy.integrate import quad\n",
    "from scipy.misc import logsumexp\n",
    "import schwimmbad\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brewer = Table.read('../data/brewer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tgas = Table.read('../data/tgas.csv')\n",
    "tgas['hd_id'] = ['240430', '240429']\n",
    "tgas['rv'] = [brewer['Vrad'][brewer['Name'] == 'HD 240430'][0], \n",
    "              brewer['Vrad'][brewer['Name'] == 'HD 240429'][0]]\n",
    "tgas['rv_error'] = 0.1 # km/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_hat(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'ra'], units=None):\n",
    "    y = np.zeros(len(names))\n",
    "        \n",
    "    default_units = dict()\n",
    "    default_units['ra'] = u.degree\n",
    "    default_units['dec'] = u.degree\n",
    "    default_units['parallax'] = u.mas\n",
    "    default_units['pmra'] = u.mas/u.yr\n",
    "    default_units['pmdec'] = u.mas/u.yr\n",
    "    default_units['rv'] = u.km/u.s\n",
    "    \n",
    "    if units is None:\n",
    "        units = [default_units[name] for name in names]\n",
    "    \n",
    "    for i,name in enumerate(names):\n",
    "        y[i] = (row[name]*default_units[name]).to(units[i]).value\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cov(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'ra'], units=None):\n",
    "    \n",
    "    default_err_units = dict()\n",
    "    default_err_units['ra'] = u.mas\n",
    "    default_err_units['dec'] = u.mas\n",
    "    default_err_units['parallax'] = u.mas\n",
    "    default_err_units['pmra'] = u.mas/u.yr\n",
    "    default_err_units['pmdec'] = u.mas/u.yr\n",
    "    default_err_units['rv'] = u.km/u.s\n",
    "    \n",
    "    if units is None:\n",
    "        units = [default_err_units[name] for name in names]\n",
    "    \n",
    "    C = np.zeros((len(names), len(names)))\n",
    "\n",
    "    # pre-load the diagonal\n",
    "    for i,name in enumerate(names):\n",
    "        full_name = \"{}_error\".format(name)\n",
    "        C[i,i] = (row[full_name]*default_err_units[name]).to(units[i]).value**2\n",
    "\n",
    "    for i,name1 in enumerate(names):\n",
    "        for j,name2 in enumerate(names):\n",
    "            if j <= i:\n",
    "                continue\n",
    "                \n",
    "            if full_name not in row: # skip if no correlations exist\n",
    "                continue\n",
    "                \n",
    "            full_name = \"{}_{}_corr\".format(name1, name2)\n",
    "            u_old = default_err_units[name1]*default_err_units[name2]\n",
    "            u_new = units[i]*units[j]\n",
    "            C[i,j] = (row[full_name] * np.sqrt(C[i,i]*C[j,j]) * u_old).to(u_new).value\n",
    "            C[j,i] = (row[full_name] * np.sqrt(C[i,i]*C[j,j]) * u_old).to(u_new).value\n",
    "            \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProbModel(object):\n",
    "        \n",
    "    def ln_posterior(self, pars):\n",
    "        \"\"\" \n",
    "        Up to a normalization constant, the log of the posterior pdf is just \n",
    "        the sum of the log likelihood plus the log prior.\n",
    "        \"\"\"\n",
    "        lnp = self.ln_prior(pars)\n",
    "        if np.isinf(lnp): # short-circuit if the prior is infinite (don't bother computing likelihood)\n",
    "            return lnp\n",
    "\n",
    "        lnL = self.ln_likelihood(pars).sum()\n",
    "        lnprob = lnp + lnL\n",
    "\n",
    "        if np.isnan(lnprob):\n",
    "            return -np.inf\n",
    "\n",
    "        return lnprob\n",
    "    \n",
    "    def __call__(self, pars):\n",
    "        return self.ln_posterior(pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component 1: wide binary\n",
    "\n",
    "The stars are a wide binary, drawn from some separation distribution \n",
    "\n",
    "### Component 2: co-moving pair\n",
    "\n",
    "The stars are co-moving but not necessarily *bound*\n",
    "\n",
    "### Component 3: chance alignment\n",
    "\n",
    "The stars are individually drawn from the field population\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmspc_to_masyr = 210.94953\n",
    "masyr_to_kmspc = 1/kmspc_to_masyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w_to_y(w):\n",
    "    x = w[:3]\n",
    "    v = w[3:]\n",
    "    dist = np.linalg.norm(x)\n",
    "    y = np.array([np.arctan2(x[1], x[0]) % (2*np.pi), # rad\n",
    "                  np.arcsin(x[2] / dist), # rad\n",
    "                  1000. / dist, # mas\n",
    "                  v[0] / dist * kmspc_to_masyr, # mas/yr\n",
    "                  v[1] / dist * kmspc_to_masyr, # mas/yr\n",
    "                  v[2]]) # km/s\n",
    "    return y\n",
    "\n",
    "def y_to_w(y):\n",
    "    dist = 1000. / y[2] # pc\n",
    "    w = np.array([dist * np.cos(y[0]) * np.cos(y[1]), # pc\n",
    "                  dist * np.sin(y[0]) * np.cos(y[1]), # pc\n",
    "                  dist * np.sin(y[1]), # pc\n",
    "                  y[3] * dist / kmspc_to_masyr, # km/s\n",
    "                  y[4] * dist / kmspc_to_masyr, # km/s\n",
    "                  y[5]]) # km/s\n",
    "    return w\n",
    "\n",
    "def ln_gaussian(x, mu, var):\n",
    "    return -0.5*((x-mu)**2/var + np.log(2*np.pi*var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MixtureModel(ProbModel):\n",
    "    \n",
    "    def __init__(self, tgas_rows, mass=[1., 1.]*u.Msun, mass_err=[0.01,0.01]*u.Msun,\n",
    "                 V1=(0.1*u.km/u.s)**2, V2=(0.1*u.km/u.s)**2, V3=(25.*u.km/u.s)**2):\n",
    "        \"\"\"\n",
    "        TODO: the right thing to do is to rotate (vra,vdec,vr) to (vx,vy,vz), but\n",
    "            this is ok at the ~10 m/s level (given their small sky separation)\n",
    "            \n",
    "        TODO: update masses\n",
    "        \n",
    "        V1 : quantity_like\n",
    "            Velocity variance of bound stars, added to account for eccentricity.\n",
    "        V2 : quantity_like\n",
    "            Velocity variance of co-moving star pairs, i.e. something like \n",
    "            the velocity difference at ~0.1 pc when they become unbound.\n",
    "        V3 : quantity_like    \n",
    "            Velocity variance assumed for field population, i.e. disk stars.\n",
    "        \"\"\" \n",
    "        assert len(tgas_rows) == 2\n",
    "        \n",
    "        self.y_hats = []\n",
    "        self.Covs = []\n",
    "        self.Cinvs = []\n",
    "        self._uvecs = []\n",
    "        self._logdets = []\n",
    "        \n",
    "        for row in tgas_rows:\n",
    "            y_hat = get_y_hat(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'rv'],\n",
    "                              units=[u.rad, u.rad, u.mas, u.mas/u.yr, u.mas/u.yr, u.km/u.s])\n",
    "            Cov = get_cov(row, names=['ra', 'dec', 'parallax', 'pmra', 'pmdec', 'rv'],\n",
    "                          units=[u.rad, u.rad, u.mas, u.mas/u.yr, u.mas/u.yr, u.km/u.s])\n",
    "            _,log_det = np.linalg.slogdet(2*np.pi*Cov)\n",
    "            \n",
    "            rep = coord.UnitSphericalRepresentation(lon=row['ra']*u.deg, \n",
    "                                                    lat=row['dec']*u.deg)\n",
    "            uvec = rep.represent_as(coord.CartesianRepresentation).xyz.value\n",
    "            \n",
    "            \n",
    "            self.y_hats.append(y_hat)\n",
    "            self.Covs.append(Cov)\n",
    "            self.Cinvs.append(np.linalg.inv(Cov))\n",
    "            self._uvecs.append(uvec)\n",
    "            self._logdets.append(log_det)\n",
    "        \n",
    "        # masses\n",
    "        self.mass = mass.to(u.Msun).value\n",
    "        self.mass_err = mass_err.to(u.Msun).value\n",
    "        self._tot_mass = np.sum(self.mass)\n",
    "        self._Mred = np.prod(self.mass) / self._tot_mass # reduced mass\n",
    "        self._G = G.to(u.pc/u.Msun*u.km**2/u.s**2).value\n",
    "        \n",
    "        # sky separation\n",
    "        coords = coord.SkyCoord(ra=tgas_rows['ra']*u.deg, \n",
    "                                dec=tgas_rows['dec']*u.deg)\n",
    "        self._cos_sep = np.cos(coords[1].separation(coords[0]))\n",
    "                \n",
    "        # some assumed hyperparameters\n",
    "        kms_sq = (u.km/u.s)**2\n",
    "        self.V1 = V1.to(kms_sq).value\n",
    "        self.V2 = V2.to(kms_sq).value\n",
    "        self.V3 = V3.to(kms_sq).value\n",
    "    \n",
    "    # ======\n",
    "    # Priors\n",
    "    # ======\n",
    "    def ln_p_dx(self, dx, a_min=1E-4, a_max=1E1): # pc\n",
    "        a_x = np.linalg.norm(dx)\n",
    "        if a_x < a_min or a_x > a_max:\n",
    "            return -np.inf\n",
    "        \n",
    "        ln_p = 0.\n",
    "        \n",
    "        # \"radial\" term\n",
    "        C = -np.log(a_max**4 - a_min**4)\n",
    "        ln_p += C - 3*np.log(a_x)\n",
    "        \n",
    "#         # angle terms\n",
    "#         ln_p += -np.log(2*np.pi)\n",
    "#         ln_p += -np.log(2.)\n",
    "        \n",
    "#         # Jacobian\n",
    "#         theta = np.arcsin(dx[2] / a_x)\n",
    "#         ln_p += 2*np.log(a_x) + np.log(np.sin(theta % np.pi))\n",
    "        \n",
    "        return ln_p\n",
    "    \n",
    "    def ln_p_dv(self, dv, dx): # km/s\n",
    "        a_x = np.linalg.norm(dx)\n",
    "        a_v = np.linalg.norm(dv)\n",
    "        \n",
    "        ln_p = 0.\n",
    "        \n",
    "        # mean velocity computed from orbital separation\n",
    "        mean_dv = np.sqrt(self._G * self._tot_mass / a_x) # km/s\n",
    "        \n",
    "        # \"radial\" term\n",
    "        ln_p += ln_gaussian(a_v, mean_dv, self.V1)\n",
    "        \n",
    "#         # angle terms\n",
    "#         ln_p += -np.log(2*np.pi)\n",
    "#         ln_p += -np.log(2)\n",
    "        \n",
    "#         # Jacobian\n",
    "#         theta = np.arcsin(dv[2] / a_v)\n",
    "#         ln_p += 2*np.log(a_v) + np.log(np.sin(theta % np.pi))\n",
    "        \n",
    "        return ln_p\n",
    "    \n",
    "    def ln_p_x(self, x, x_max=1000., x_min=-1000.): #pc\n",
    "        if np.any(x < x_min) or np.any(x > x_max):\n",
    "            return -np.inf\n",
    "        return -len(x) * np.log(x_max-x_min)\n",
    "\n",
    "    def ln_p_v(self, v, mu=0., var=None): # km/s\n",
    "        if var is None:\n",
    "            var = self.V3 # field\n",
    "        return -0.5 * np.sum((v-mu)**2 / var + np.log(2*np.pi*var))\n",
    "    \n",
    "    def unpack_pars(self, pars):\n",
    "        \"\"\"\n",
    "        We sample over the 6D Cartesian phase-space parameters of the barycenter\n",
    "        of the pair and the separation from star1 to star2 -- that is, the \n",
    "        separation is defined as positive from star1 to star2. \n",
    "        \n",
    "        Positions are in [pc]\n",
    "        Velocities in [km/s]\n",
    "        Masses in [Msun]\n",
    "        \"\"\"\n",
    "        (x1, y1, z1, vx1, vy1, vz1, \n",
    "         x2, y2, z2, vx2, vy2, vz2, \n",
    "         M1, M2, # masses\n",
    "         f1, f2) = pars\n",
    "        \n",
    "        # construct 6D vectors of phase-space coordinates\n",
    "        w1 = np.array([x1, y1, z1, vx1, vy1, vz1])\n",
    "        w2 = np.array([x2, y2, z2, vx2, vy2, vz2])\n",
    "        dw = w2 - w1\n",
    "        \n",
    "        # mass ratio factors\n",
    "        fac1 = self._Mred / self.mass[0]\n",
    "        \n",
    "        # position, velocity of star 1, star2:\n",
    "        w_bary = w1 + fac1*dw\n",
    "        \n",
    "        mix_weights = [f1, f2, 1-(f1+f2)]\n",
    "        \n",
    "        return w1, w2, w_bary, dw, [M1, M2], mix_weights\n",
    "    \n",
    "    def ln_prior1(self, w1, w2, w_bary, dw):\n",
    "        \"\"\"\n",
    "        Compute the log-prior for component 1 of the mixture model:\n",
    "        wide binary\n",
    "        \"\"\"\n",
    "        ln_p = 0.\n",
    "        \n",
    "        # prior terms\n",
    "        ln_p += self.ln_p_dx(dw[:3])\n",
    "        ln_p += self.ln_p_dv(dw[3:], dx=dw[:3])\n",
    "        ln_p += self.ln_p_x(w_bary[:3])\n",
    "        ln_p += self.ln_p_v(w_bary[3:])\n",
    "        \n",
    "        if not np.isfinite(ln_p):\n",
    "            return -np.inf\n",
    "        \n",
    "        return ln_p\n",
    "        \n",
    "    def ln_prior2(self, w1, w2, w_bary, dw):\n",
    "        \"\"\"\n",
    "        Compute the log-prior for component 2 of the mixture model:\n",
    "        unbound but comoving\n",
    "        \"\"\"\n",
    "        ln_p = 0.\n",
    "        \n",
    "        # prior terms\n",
    "        ln_p += self.ln_p_x(w1[:3])\n",
    "        ln_p += self.ln_p_x(w2[:3])\n",
    "        ln_p += self.ln_p_v(w1[3:])\n",
    "        ln_p += self.ln_p_v(w2[3:], w1[3:], self.V2)\n",
    "        \n",
    "        if not np.isfinite(ln_p):\n",
    "            return -np.inf\n",
    "        \n",
    "        return ln_p\n",
    "    \n",
    "    def ln_prior3(self, w1, w2, w_bary, dw):\n",
    "        \"\"\"\n",
    "        Compute the log-prior for component 3 of the mixture model:\n",
    "        two independent draws from the field population\n",
    "        \"\"\"\n",
    "        ln_p = 0.\n",
    "        \n",
    "        # prior terms\n",
    "        ln_p += self.ln_p_x(w1[:3])\n",
    "        ln_p += self.ln_p_x(w2[:3])\n",
    "        ln_p += self.ln_p_v(w1[3:])\n",
    "        ln_p += self.ln_p_v(w2[3:])\n",
    "        \n",
    "        if not np.isfinite(ln_p):\n",
    "            return -np.inf\n",
    "        \n",
    "        return ln_p\n",
    "    \n",
    "    def ln_prior(self, pars):        \n",
    "        w1, w2, w_bary, dw, _, mix_weights = self.unpack_pars(pars)\n",
    "        \n",
    "        ln_p = 0.\n",
    "        \n",
    "        # uniform prior on weights\n",
    "        if (mix_weights[0] < 0 or mix_weights[0] > 1. or \n",
    "            mix_weights[1] < 0 or mix_weights[1] > 1 or \n",
    "            (mix_weights[0]+mix_weights[1]) > 1):\n",
    "            return -np.inf\n",
    "        \n",
    "        lnprob1 = self.ln_prior1(w1, w2, w_bary, dw)\n",
    "        lnprob2 = self.ln_prior2(w1, w2, w_bary, dw)\n",
    "        lnprob3 = self.ln_prior3(w1, w2, w_bary, dw)\n",
    "        lnprobs = [lnprob1, lnprob2, lnprob3]\n",
    "        \n",
    "        if np.any(np.logical_not(np.isfinite(lnprobs))):\n",
    "            return np.array([-np.inf])\n",
    "        \n",
    "        return logsumexp(lnprobs, b=mix_weights)\n",
    "        \n",
    "    def ln_likelihood(self, pars):\n",
    "        w1, w2, _, _, masses, _ = self.unpack_pars(pars)\n",
    "        ws = [w1, w2]\n",
    "        \n",
    "        ln_l = 0.\n",
    "        for i in range(2):\n",
    "            # convert Cartesian to [ra, dec, parallax, mu_ra, mu_dec, rv]\n",
    "            y = w_to_y(ws[i])\n",
    "        \n",
    "            # difference in data space\n",
    "            dy = self.y_hats[i] - y\n",
    "        \n",
    "            # kinematic data\n",
    "            ln_l += -0.5 * self._logdets[i] - 0.5 * dy.T @ self.Cinvs[i] @ dy\n",
    "              \n",
    "            # mass\n",
    "            ln_l += ln_gaussian(masses[i], self.mass[i], self.mass_err[i])\n",
    "        \n",
    "        return ln_l\n",
    "    \n",
    "    def get_p0(self, size=1, scale=1E-3):\n",
    "        try:\n",
    "            len(size)\n",
    "        except:\n",
    "            size = (size,)\n",
    "        p0 = np.zeros(size+(16,))\n",
    "        \n",
    "        y_hats = [np.random.multivariate_normal(yh, (1E-3)**2*Cov, size=size)\n",
    "                  for yh,Cov in zip(self.y_hats, self.Covs)]\n",
    "        \n",
    "        p0[...,:6] = y_to_w(y_hats[0].T).T\n",
    "        p0[...,6:12] = y_to_w(y_hats[1].T).T\n",
    "        p0[...,12:14] = np.random.normal(self.mass, self.mass_err*scale, size=size+(2,))\n",
    "        p0[...,14:16] = np.random.normal([0.5, 0.1], scale, size=size+(2,))\n",
    "        \n",
    "        return np.squeeze(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MixtureModel(tgas, mass=[1., 1.07]*u.Msun, mass_err=[0.01, 0.01]*u.Msun, V1=(1E-3*u.km/u.s)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = model.get_p0()\n",
    "ndim = len(p0)\n",
    "model.ln_likelihood(p0), model.ln_prior(p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PTSampler instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntemps = 32\n",
    "betas = np.logspace(0, -8, ntemps)\n",
    "nwalkers = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_burnin = 1024\n",
    "n_mcmc = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_p0 = model.get_p0(size=(ntemps,nwalkers))\n",
    "ndim = all_p0.shape[-1]\n",
    "with schwimmbad.MultiPool() as pool:\n",
    "    pt_sampler = emcee.PTSampler(ntemps, nwalkers, ndim, \n",
    "                                 model.ln_likelihood, model.ln_prior,\n",
    "                                 betas=betas, pool=pool)\n",
    "    \n",
    "    for res in tqdm.tqdm_notebook(pt_sampler.sample(all_p0, iterations=n_burnin), desc='Burn-in'):\n",
    "        pass\n",
    "    \n",
    "    pos,_,_ = res\n",
    "    pt_sampler.reset()\n",
    "    \n",
    "    for res in tqdm.tqdm_notebook(pt_sampler.sample(pos, iterations=n_mcmc), desc='Production'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot_walkers = 32\n",
    "alpha = 0.1\n",
    "\n",
    "fig,axes = plt.subplots(6, 3, figsize=(15,15), sharex=True)\n",
    "\n",
    "temp = 0\n",
    "\n",
    "for k in range(0,6):\n",
    "    for j in range(n_plot_walkers):\n",
    "        axes[k,0].plot(pt_sampler.chain[temp,j,:,k], marker='', alpha=alpha, \n",
    "                       drawstyle='steps-mid', color='k')\n",
    "        \n",
    "for k in range(0,6):\n",
    "    for j in range(n_plot_walkers):\n",
    "        axes[k,1].plot(pt_sampler.chain[temp,j,:,k+6], marker='', alpha=alpha, \n",
    "                       drawstyle='steps-mid', color='k')\n",
    "        \n",
    "for k in range(0,4):\n",
    "    for j in range(n_plot_walkers):\n",
    "        axes[k,2].plot(pt_sampler.chain[temp,j,:,k+12], marker='', alpha=alpha, \n",
    "                       drawstyle='steps-mid', color='k')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[-1,-1].set_visible(False)\n",
    "\n",
    "# fig.savefig('../plots/trace_pt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatchain = np.vstack(pt_sampler.chain[0,:,::8])\n",
    "flatchain = np.vstack((flatchain.T, 1-(flatchain[:,-2]+flatchain[:,-1]))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(flatchain, bins=64, plot_datapoints=False)\n",
    "#                     labels=['$r_1$ [pc]', r'$v_{\\alpha,1}$ [km/s]', r'$v_{\\delta,1}$ [km/s]', '$v_{r,1}$ [km/s]', \n",
    "#                             '$r_2$ [pc]', r'$v_{\\alpha,2}$ [km/s]', r'$v_{\\delta,2}$ [km/s]', '$v_{r,2}$ [km/s]', \n",
    "#                             r'$\\ln a/{\\rm pc}$', '$f_1$ (bound)', '$f_2$ (comoving)', '$f_3$ (field)'])\n",
    "# fig.savefig('../plots/corner.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dx = np.linalg.norm(flatchain[:,6:9]-flatchain[:,0:3], axis=-1)\n",
    "plt.hist(dx, bins=np.logspace(-3, 1, 16))\n",
    "plt.xscale('log')\n",
    "plt.axvline(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('pt_chain_temp0.npy', pt_sampler.chain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard ensemble sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 256\n",
    "n_burnin = 512\n",
    "n_mcmc = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# all_p0 = model.get_p0(size=nwalkers)\n",
    "# ndim = all_p0.shape[1]\n",
    "# with schwimmbad.MultiPool() as pool:\n",
    "#     sampler = emcee.EnsembleSampler(nwalkers, ndim, model, pool=pool)\n",
    "    \n",
    "#     for res in tqdm.tqdm_notebook(sampler.sample(all_p0, iterations=n_burnin), desc='Burn-in'):\n",
    "#         pass\n",
    "    \n",
    "#     pos,_,_ = res\n",
    "#     sampler.reset()\n",
    "    \n",
    "#     for res in tqdm.tqdm_notebook(sampler.sample(pos, iterations=n_mcmc), desc='Production'):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_plot_walkers = 128\n",
    "# alpha = 0.1\n",
    "\n",
    "# fig,axes = plt.subplots(6, 3, figsize=(15,15), sharex=True)\n",
    "\n",
    "# for k in range(0,6):\n",
    "#     for j in range(n_plot_walkers):\n",
    "#         axes[k,0].plot(sampler.chain[j,:,k], marker='', alpha=alpha, \n",
    "#                        drawstyle='steps-mid', color='k')\n",
    "        \n",
    "# for k in range(0,6):\n",
    "#     for j in range(n_plot_walkers):\n",
    "#         axes[k,1].plot(sampler.chain[j,:,k+6], marker='', alpha=alpha, \n",
    "#                        drawstyle='steps-mid', color='k')\n",
    "        \n",
    "# for k in range(0,4):\n",
    "#     for j in range(n_plot_walkers):\n",
    "#         axes[k,2].plot(sampler.chain[j,:,k+12], marker='', alpha=alpha, \n",
    "#                        drawstyle='steps-mid', color='k')\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# axes[-1,-1].set_visible(False)\n",
    "\n",
    "# fig.savefig('../plots/trace.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # flatchain = sampler.flatchain[:,[0,1,2,3,8,9,10]]\n",
    "# flatchain = sampler.flatchain\n",
    "# flatchain = np.vstack((flatchain.T, 1-(flatchain[:,-2]+flatchain[:,-1]))).T\n",
    "\n",
    "# fig = corner.corner(flatchain, bins=64, plot_datapoints=False,\n",
    "#                     labels=['$r_1$ [pc]', r'$v_{\\alpha,1}$ [km/s]', r'$v_{\\delta,1}$ [km/s]', '$v_{r,1}$ [km/s]', \n",
    "#                             '$r_2$ [pc]', r'$v_{\\alpha,2}$ [km/s]', r'$v_{\\delta,2}$ [km/s]', '$v_{r,2}$ [km/s]', \n",
    "#                             r'$\\ln a/{\\rm pc}$', '$f_1$ (bound)', '$f_2$ (comoving)', '$f_3$ (field)'])\n",
    "# del fig"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}